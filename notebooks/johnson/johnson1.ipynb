{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0,'../..'); sys.path.insert(0,'/Users/ryan/github/lltk')\n",
    "from lltk import *\n",
    "from abslithist import *\n",
    "from abslithist.words import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_texts='/Users/ryan/lltk_data/corpora/wimsatt/texts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addison.Spectator106.txt               Hazlitt.LoveOfTheCountry.txt\n",
      "Addison.Spectator177.txt               Johnson.Idler10.txt\n",
      "Addison.Spectator267.txt               Johnson.LifeOfPope.txt\n",
      "Hazlitt.DrydenAndPope.txt              Johnson.Rambler2.txt\n",
      "Hazlitt.FirstAcquaintanceWithPoets.txt\n"
     ]
    }
   ],
   "source": [
    "!ls {path_texts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn=os.path.join(path_texts,'Johnson.Rambler2.txt')\n",
    "with open(fn) as f: txt=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !spacy download en_core_web_sm\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[the, quick, brown, fox]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_noun_phrase(sent, target_token):\n",
    "    # Traverse up to the head of the noun phrase\n",
    "    while target_token.dep_ not in (\"ROOT\", \"conj\") and target_token.head.pos_ in (\"NOUN\", \"PROPN\", \"PRON\"):\n",
    "        target_token = target_token.head\n",
    "        break\n",
    "\n",
    "    # Collect all tokens in the noun phrase\n",
    "    noun_phrase_tokens = [token for token in target_token.subtree]\n",
    "    \n",
    "    # Return the combined text of the noun phrase\n",
    "    return noun_phrase_tokens\n",
    "\n",
    "# Example usage\n",
    "text = \"The hunter of the quick brown fox jumps over the lazy dog.\"\n",
    "sent = nlp(text)\n",
    "word = \"fox\"\n",
    "noun_phrase = find_noun_phrase(sent, sent[5])\n",
    "noun_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('long ease and indulgence')\n",
    "doc = nlp('There is a new character and a new consequence; a new thrill, a new joy, and sadness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCONJ cc and\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    for w in sent:\n",
    "        if w.text == 'and':\n",
    "            print(w.pos_, w.dep_,w)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conjunct_noun_phrases(sent):\n",
    "    nl=list(sent.noun_chunks)\n",
    "    o=[]\n",
    "    done=set()\n",
    "    for i,n in enumerate(nl):\n",
    "        if i in done: continue\n",
    "        no=[n]\n",
    "        if n.conjuncts:\n",
    "            for conj in n.conjuncts:\n",
    "                for i2,n2 in enumerate(nl):\n",
    "                    if i2 in done: continue\n",
    "                    if i<i2 and conj.i in {w.i for w in n2}:\n",
    "                        no.append(n2)\n",
    "                        done.add(i2)\n",
    "        if len(no)>1:\n",
    "            o.append(no)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_dep_span(sent, tok, deps={'conj','cc','prep'}):\n",
    "#     head=tok.head\n",
    "#     foot = None\n",
    "#     for w in sent:\n",
    "#         if w.head == tok:\n",
    "#             foot = w\n",
    "#     if head and foot:# and sent[head].pos_ == sent[foot].pos_:\n",
    "#         span=sent[head.i:foot.i+1]\n",
    "#         return span\n",
    "\n",
    "\n",
    "\n",
    "# def get_conjunct_words(sent, deps={'conj','cc','prep'}):\n",
    "#     o=defaultdict(list)\n",
    "#     for w in sent:\n",
    "#         print([w,'-->',w.dep_,'-->',w.head])\n",
    "#         if w.dep_ in deps:\n",
    "#             v=get_dep_span(sent, w)\n",
    "#             if v:\n",
    "#                 o[w]=v\n",
    "#     #         print('!',w,w.dep_,w.head)\n",
    "#     #         key=w\n",
    "#     #         out=[]\n",
    "#     #         while key.head and key.head not in set(out) and key.dep_ in deps:\n",
    "#     #             out.extend([key,key.head])\n",
    "#     #             key=key.head\n",
    "#     #         o[key].extend(list(set(out)))\n",
    "#     # for k in o:\n",
    "#     #     o[k]=[v for v in o[k] if v.dep_ in deps]\n",
    "#     #     o[k]=sent[min(o[k]).i : max(o[k]).i+1]\n",
    "#     o=[list(v) for v in o.values()]\n",
    "#     o.sort(key = lambda v: -len(v))\n",
    "#     o2=o\n",
    "#     # done=set()\n",
    "#     # for v in o:\n",
    "#     #     if not all(x in done for x in v):\n",
    "#     #         done.update(set(v))\n",
    "#     #         print(done)\n",
    "#     #         o2.append(v)\n",
    "#     return [\n",
    "#         detokenize([x.text for x in v])\n",
    "#         for v in o2\n",
    "#         if len(v)>1\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DT'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp('the')[0].tag_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_head_foot(sent, tok):\n",
    "    head=tok.head\n",
    "    foot = None\n",
    "    for w in sent:\n",
    "        if w.head == tok or w.head == tok.head and w.pos_ not in {'PUNCT'}:\n",
    "            foot = w\n",
    "    return head,foot\n",
    "\n",
    "def find_phrase_subtree(sent,tok, stop=None):\n",
    "    # o=[x for x in sent if (x==tok or x.head == tok)]\n",
    "    # if stop != None: o=[x for x in o if x.i<stop]\n",
    "    # print('>>',tok,o)\n",
    "    o = [x for x in tok.subtree if (stop is None or x.i<stop)]\n",
    "    o=sent[min(o).i : max(o).i+1]\n",
    "    print('>>>',tok,o)\n",
    "    return tuple(o)\n",
    "\n",
    "def find_phrase_span(sent,tok, stop=None):\n",
    "    o=[x for x in sent if (x==tok or x.head == tok) and (stop == None or x.i<stop) and x.i>=tok.i]\n",
    "    o=sent[min(o).i : max(o).i+1]\n",
    "    print('>>>',tok,o)\n",
    "    return tuple(o)\n",
    "\n",
    "\n",
    "def parallel_phrases(phr1,phr2,tok,pos_aggregation = {\n",
    "        \"PROPN\": \"NOUN\",\n",
    "        \"CCONJ\": \"CONJ\",\n",
    "        \"SCONJ\": \"CONJ\",\n",
    "    }):\n",
    "    il=[x.i for x in phr1] + [tok.i] + [x.i for x in phr2]\n",
    "    il2=list(range(phr1[0].i, phr2[-1].i+1))\n",
    "    print(il)\n",
    "    print(il2)\n",
    "    if il == il2:\n",
    "        phr1=[x for x in phr1 if x.pos_ not in {'PUNCT'}]\n",
    "        phr2=[x for x in phr2 if x.pos_ not in {'PUNCT'}]\n",
    "        while phr1 and phr1[0].pos_=='PRON': phr1=phr1[1:]\n",
    "        while phr2 and phr2[0].pos_=='PRON': phr2=phr2[1:]\n",
    "        l1=[pos_aggregation.get(x.pos_,x.pos_) for x in phr1]\n",
    "        l2=[pos_aggregation.get(x.pos_,x.pos_) for x in phr2]\n",
    "        print()\n",
    "        print(l1)\n",
    "        print(l2)\n",
    "        print()\n",
    "        if l1==l2:\n",
    "            return (tuple(phr1),tuple(phr2))\n",
    "    return None,None\n",
    "\n",
    "def get_conjunct_words(sent, deps={'cc','prep'}):\n",
    "    o=[]\n",
    "    for w in sent:\n",
    "        print(w.i,w,w.dep_,w.head)\n",
    "        if w.dep_ in deps:\n",
    "            head,foot=get_head_foot(sent,w)\n",
    "            print((head,foot))\n",
    "            if head and foot:\n",
    "                headphr,footphr = find_phrase_subtree(sent,head,stop=w.i), find_phrase_subtree(sent,foot)\n",
    "                headphr,footphr = parallel_phrases(headphr,footphr,w)\n",
    "                if headphr and footphr:\n",
    "                    o.append([headphr,w,footphr])\n",
    "                else:\n",
    "                    headphr,footphr = find_phrase_span(sent,head,stop=w.i), find_phrase_span(sent,foot)\n",
    "                    headphr,footphr = parallel_phrases(headphr,footphr,w)\n",
    "                    if headphr and footphr:\n",
    "                        o.append([headphr,w,footphr])\n",
    "                    # if len(headphr)>1:\n",
    "                        # print(o[-1])\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 The det flights\n",
      "1 natural amod flights\n",
      "2 flights nsubj are\n",
      "3 of prep flights\n",
      "(flights, mind)\n",
      ">>> flights The natural flights\n",
      ">>> mind the human mind\n",
      "[0, 1, 2, 3, 4, 5, 6]\n",
      "[0, 1, 2, 3, 4, 5, 6]\n",
      "\n",
      "['DET', 'ADJ', 'NOUN']\n",
      "['DET', 'ADJ', 'NOUN']\n",
      "\n",
      "4 the det mind\n",
      "5 human amod mind\n",
      "6 mind pobj of\n",
      "7 are ROOT are\n",
      "8 not neg are\n",
      "9 from prep are\n",
      "(are, hope)\n",
      ">>> are The natural flights of the human mind are not\n",
      ">>> hope from hope to hope\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 15, 16, 17, 18]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      ">>> are are not\n",
      ">>> hope hope\n",
      "[7, 8, 9, 18]\n",
      "[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "10 pleasure pobj from\n",
      "11 to prep from\n",
      "(from, pleasure)\n",
      ">>> from from pleasure\n",
      ">>> pleasure pleasure\n",
      "[9, 10, 11, 12]\n",
      "[9, 10, 11, 12]\n",
      "\n",
      "['ADP', 'NOUN']\n",
      "['VERB']\n",
      "\n",
      ">>> from from pleasure\n",
      ">>> pleasure pleasure\n",
      "[9, 10, 11, 12]\n",
      "[9, 10, 11, 12]\n",
      "\n",
      "['ADP', 'NOUN']\n",
      "['VERB']\n",
      "\n",
      "12 pleasure pobj to\n",
      "13 , punct are\n",
      "14 but cc are\n",
      "(are, hope)\n",
      ">>> are The natural flights of the human mind are not from pleasure to pleasure,\n",
      ">>> hope from hope to hope\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "\n",
      "['DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'AUX', 'PART', 'ADP', 'NOUN', 'ADP', 'VERB']\n",
      "['ADP', 'NOUN', 'AUX', 'VERB']\n",
      "\n",
      ">>> are are not from pleasure to pleasure,\n",
      ">>> hope hope\n",
      "[7, 8, 9, 10, 11, 12, 13, 14, 18]\n",
      "[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "15 from prep hope\n",
      "(hope, to)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m sent\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe natural flights of the human mind are not from pleasure to pleasure, but from hope to hope.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# sent='He did not court the candour, but dared the judgment of the reader'\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# sent='the breaking in a flower pot, or fall of a china jar.'\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# sent='Who knows if the quick brown fox without the lazy gray seal really want what they want?'\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mget_conjunct_words\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 57\u001b[0m, in \u001b[0;36mget_conjunct_words\u001b[0;34m(sent, deps)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m((head,foot))\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m foot:\n\u001b[0;32m---> 57\u001b[0m     headphr,footphr \u001b[38;5;241m=\u001b[39m \u001b[43mfind_phrase_subtree\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m, find_phrase_subtree(sent,foot)\n\u001b[1;32m     58\u001b[0m     headphr,footphr \u001b[38;5;241m=\u001b[39m parallel_phrases(headphr,footphr,w)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m headphr \u001b[38;5;129;01mand\u001b[39;00m footphr:\n",
      "Cell \u001b[0;32mIn[13], line 14\u001b[0m, in \u001b[0;36mfind_phrase_subtree\u001b[0;34m(sent, tok, stop)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_phrase_subtree\u001b[39m(sent,tok, stop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# o=[x for x in sent if (x==tok or x.head == tok)]\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# if stop != None: o=[x for x in o if x.i<stop]\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# print('>>',tok,o)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     o \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tok\u001b[38;5;241m.\u001b[39msubtree \u001b[38;5;28;01mif\u001b[39;00m (stop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m x\u001b[38;5;241m.\u001b[39mi\u001b[38;5;241m<\u001b[39mstop)]\n\u001b[0;32m---> 14\u001b[0m     o\u001b[38;5;241m=\u001b[39msent[\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mi : \u001b[38;5;28mmax\u001b[39m(o)\u001b[38;5;241m.\u001b[39mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>>>\u001b[39m\u001b[38;5;124m'\u001b[39m,tok,o)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(o)\n",
      "\u001b[0;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "sent='smoothness without a fair fight is very bad'\n",
    "sent='gross polish, fruitless grace, but damn foolishness'\n",
    "sent='The natural flights of the human mind are not from pleasure to pleasure, but from hope to hope.'\n",
    "# sent='He did not court the candour, but dared the judgment of the reader'\n",
    "# sent='the breaking in a flower pot, or fall of a china jar.'\n",
    "# sent='Who knows if the quick brown fox without the lazy gray seal really want what they want?'\n",
    "get_conjunct_words(nlp(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.find_noun_phrase(sent, target_token)>"
      ]
     },
     "execution_count": 788,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_noun_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[polish, grace, damn foolishness]]"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_conjunct_noun_phrases(nlp(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The quick brown fox'"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for w in nlp(sent):\n",
    "#     siblings = [sib for sib in w.head.children if sib.dep_ == 'conj']\n",
    "#     print(w.i, w, w.dep_, w.head, list(w.subtree), siblings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! smoothness\n",
      "[is, [smoothness, is]]\n",
      "! without\n",
      "[is, [without, is]]\n",
      "! a\n",
      "[is, [a, fight, fight, without, without, is]]\n",
      "! fight\n",
      "[is, [fight, without, without, is]]\n",
      "[smoothness, is, without, is, without, a, fight, is, without, fight, is]\n",
      "smoothness without a fight is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['smoothness without a fight is']"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parallel_noun_phrases(sent):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1=nl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1[0].i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nl[3].conjuncts[0].i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "That the mind of man is never satisfied with the objects immediately before it, but is always breaking away from the present moment, and losing itself in schemes of future felicity; and that we forget the proper use of the time, now in our power, to provide for the enjoyment of that which, perhaps, may never be granted us, has been frequently remarked; and as this practice is a commodious subject of raillery to the gay, and of declamation to the serious, it has been ridiculed with all the pleasantry of wit, and exaggerated with all the amplifications of rhetorick."
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "corp1 = lltk.Corpus('ecco_tcp')\n",
    "corp2 = lltk.Corpus('tedjdh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3101, 3778, 2188)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corp1.meta), len(corp2.meta), len(set(corp1.meta.index) & set(corp2.meta.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
